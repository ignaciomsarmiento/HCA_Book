[["index.html", "Haciendo Ciencia Abierta 1 Prefacio", " Haciendo Ciencia Abierta Ignacio Sarmiento Barbieri | Gustavo Castillo-Alvarez 2024-06-17 1 Prefacio La ciencia social debe ser accesible para una amplia interpretación crítica y contribución, promoviendo sociedades abiertas. Este libro complementa al taller “Haciendo Ciencia Abierta” que tiene como objetivo fortalecer las prácticas de investigación dentro de la comunidad hispanohablante. Sirve como un acompañamiento, proporcionando una guía detallada y recursos adicionales para los participantes. El Libro como el taller se centrará en tres áreas principales: Ética y Transparencia en el Diseño de Investigación: Aquí, se abordará la importancia de los planes de preanálisis, destacando cómo estos pueden contribuir a una mayor transparencia y confianza en los resultados de la investigación. Reproducibilidad y Flujos de Trabajo Reproducibles: En esta sección, se hará énfasis en el control de versiones mediante GitHub y la presentación efectiva de los resultados de investigación utilizando RMarkdown. La reproducibilidad es un pilar fundamental para asegurar que los hallazgos puedan ser verificados y utilizados como base para investigaciones futuras. Gestión Segura de Datos: Se destacarán las prácticas éticas de recopilación de datos y el archivado a largo plazo utilizando herramientas como OSF y Zenodo. La gestión adecuada de datos no solo protege la integridad de la investigación, sino que también garantiza que los datos estén disponibles para futuros investigadores de manera segura y organizada. Este libro está dirigido a estudiantes de posgrado, estudiantes de último año de pregrado y profesores de ciencias sociales en Colombia y América Latina. Queremos equipar a estos académicos con las herramientas y conocimientos necesarios para llevar a cabo investigaciones de alta calidad, que sean éticas, transparentes y reproducibles. En un mundo donde la información y la desinformación compiten por la atención pública, es crucial que la investigación en ciencias sociales mantenga altos estándares de rigor y apertura. Este libro pretende ser una guía para lograr estos objetivos, fomentando una comunidad de investigación que valore y practique la ciencia abierta. El contenido y enfoque de este libro están inspirados y adoptan materiales del texto “Transparent and Reproducible Social Science Research: How to Do Open Science” de Christensen, Garret; Freese, Jeremy; y Miguel, Edward, publicado por University of California Press. Este valioso recurso ha servido como fundamento para estructurar nuestro programa y enriquecer nuestras discusiones sobre la importancia de la ciencia abierta. Agradecemos a la Berkeley Initiative for Transparency in the Social Sciences (BITSS), una iniciativa del Center for Effective Global Action (CEGA) de la Universidad de California, en Berkeley y a la Universidad de Los Andes por su apoyo y esperamos que los conocimientos y habilidades adquiridos aquí se extiendan más allá del aula, contribuyendo al avance de la ciencia social en nuestra región. "],["intro.html", " 2 Introducción 2.1 La Confiabilidad de la Evidencia 2.2 Cambios de la AEA sobre Transparencia y el Editor de Datos 2.3 Mejorar la Confiabilidad de la Investigación", " 2 Introducción El trabajo empírico, especialmente, la investigación en ciencias sociales, enfrenta una crisis de confianza debido a la falta de transparencia y casos de fraude. La toma de decisiones informadas en áreas como la salud, la economía y la política depende en gran medida de un trabajo de datos confiables. Sin embargo, la proliferación de casos de fraude y la falta de transparencia en la metodologías empíricas han generado una creciente desconfianza en los resultados obtenidos. Este libro tiene como objetivo abordar esta problemática mediante la implementación de herramientas y estrategias que mejoren la rigurosidad y la credibilidad en el trabajo empírico y especialmente en la investigación. 2.1 La Confiabilidad de la Evidencia ¿Cuán confiable es la evidencia actual que sustenta la toma de decisiones? Muchos creen que no es lo suficientemente confiable. Una crisis de confianza ha surgido en la investigación en ciencias sociales, con voces influyentes tanto dentro como fuera del ámbito académico señalando que la investigación relevante para la política es a menudo menos fiable de lo que se afirma, o incluso incorrecta. La creencia popular de que se pueden manipular las estadísticas para obtener cualquier respuesta deseada refleja esta pérdida de fe en la investigación, y la percepción de que muchos hallazgos científicos son simplemente abogacía disfrazada de ciencia. La exactitud y la credibilidad de la evidencia utilizada son extremadamente importantes y en este libro proporciona herramientas para aumentar el rigor y la credibilidad de el trabajo empírico. 2.1.1 Fraude En años recientes en la investigación han salido a la luz numerosos casos de fraude, quizás el caso más famoso recientemente es el de Francesca Gino donde se encontraron inconsistencias significativas en los datos presentados en sus publicaciones. Los responsables de dar a la luz con estas practicas cuestionadas fue el sitio web Data Colada que se dedica a promover la transparencia y la reproducibilidad en la investigación científica mediante la exposición de casos de mala praxis y fraude académico. Caso de Francesca Gino Francesca Gino, una destacada profesora de la Escuela de Negocios de Harvard, se vio envuelta en un escándalo de fraude académico que conmocionó al mundo de la investigación en ciencias sociales. Gino, conocida por su trabajo en comportamiento organizacional y psicología, fue acusada de manipular datos en varios estudios publicados en prestigiosas revistas académicas. Las acusaciones llevaron a una revisión exhaustiva de sus publicaciones, resultando en la retractación de varios artículos. Este escándalo no solo afectó la reputación de Gino, sino que también tuvo un impacto negativo en sus coautores y en la credibilidad de la institución que representaba. La Escuela de Negocios de Harvard se vio obligada a revisar sus procedimientos y políticas para prevenir futuros casos de mala conducta. Este caso subraya la importancia de la transparencia y la reproducibilidad en la investigación académica. La manipulación de datos no solo distorsiona la verdad científica, sino que también daña la confianza del público en la ciencia. La comunidad académica debe tomar medidas proactivas para garantizar la integridad de la investigación y protegerse contra el fraude. Puede ver mas del caso aqui Aunque el fraude es la excepción y no la regla, estos casos son síntomas dramáticos de problemas subyacentes más amplios. Al igual que en otros casos de fraude, las acciones de Gino fueron vistas como un síntoma de problemas más profundos en el sistema de investigación, donde las presiones para publicar y obtener reconocimiento pueden llevar a algunos académicos a cometer actos deshonestos. Es esencial fomentar una cultura de integridad y rigor científico para preservar la validez y la utilidad de la investigación en ciencias sociales. 2.1.2 Incapacidad para reproducir resultados Un segundo problema significativo en la practica empírica como en la investigación es la incapacidad de reproducir los resultados, lo cual es crucial para validar la fiabilidad de los hallazgos. Por ejemplo en economía el problema es particularmente importante donde muchos de los resultados son imposibles de reproducir. La siguiente tabla resume varios estudios que intentaron reproducir resultados de trabajos empíricos: Estudio Número de artículos (solicitudes) Reproducción intentada Reproducción exitosa Tasa de reproducción Tasa de reproducción por artículo empírico Dewald, Thursby, and Anderson (1986) antes del cambio de política 62 5 3 60.0% 4.8% Dewald, Thursby, and Anderson (1986) después del cambio de política 92 3 2 66.7% 2.2% McCullough and Vinod (2003) 193 62 14 22.6% 7.3% Chang and Li (2015) 67 59 29 49.2% 43.3% Dewald, Thursby, and Anderson (1986) intentaron reproducir trabajos publicados en el Journal of Money, Credit and Banking antes y después del cambio de política en la revista que solicitaba a los autores compartir los datos. Para los artículos antes del cambio , se intentó replicar 5 de 62 artículos, logrando éxito en 3 casos (60.0%). Después del cambio de política, la tasa de éxito aumentó ligeramente al 66.7%, aunque el número absoluto de reproducciones exitosas fue bajo.Por otro lado, McCullough and Vinod (2003) intentaron reproducir 62 de 193 artículos, con una tasa de éxito del 22.6%. Finalmente y mas recientemente, Chang and Li (2015) intentaron replicar 59 de 67 artículos, logrando éxito en 29 casos (49.2%). La capacidad de replicar estudios es esencial para confirmar la validez de los resultados en ciencias sociales. Las tasas de reproducción varían significativamente, destacando la necesidad de políticas más robustas para mejorar la transparencia y reproducibilidad de los hallazgos. Estos problemas subrayan la importancia de fomentar una cultura académica que valore la reproducción y la transparencia, asegurando que las conclusiones sean fiables y puedan ser utilizadas de manera efectiva en la toma de decisiones. 2.2 Cambios de la AEA sobre Transparencia y el Editor de Datos En respuesta a los crecientes problemas de reproducibilidad y transparencia en la investigación en ciencias sociales, la Asociación Estadounidense de Economía (AEA, por sus siglas en inglés) ha implementado cambios significativos en sus políticas editoriales. Estos cambios están diseñados para mejorar la credibilidad y la rigurosidad de la investigación publicada en sus revistas. Una de las medidas clave ha sido la implementación de requisitos más estrictos para la divulgación de datos y métodos. Los autores ahora deben proporcionar acceso a los datos y a los códigos de análisis utilizados en sus estudios, permitiendo a otros investigadores verificar los resultados de manera independiente. Esta medida busca reducir el riesgo de errores y aumentar la transparencia en el proceso de investigación. Además de los requisitos de divulgación de datos, la AEA ha creado el puesto de Editor de Datos (Data Editor). Este rol es fundamental para garantizar que los datos y códigos proporcionados por los autores cumplan con los estándares de calidad y transparencia establecidos por la asociación. El Editor de Datos revisa los materiales de apoyo de los estudios aceptados para publicación, asegurándose de que sean completos, precisos y suficientes para permitir la replicación de los resultados. Este paso adicional en el proceso de revisión editorial busca fortalecer la confianza en los hallazgos publicados y promover una cultura de apertura y responsabilidad en la comunidad investigadora. Estos esfuerzos de la AEA representan un paso importante hacia la mejora de la integridad en la investigación económica. Al exigir la divulgación de datos y la revisión rigurosa de los mismos, la AEA no solo mejora la calidad de las investigaciones publicadas, sino que también fomenta un ambiente de mayor colaboración y verificación entre los investigadores. La esperanza es que estas iniciativas inspiren a otras organizaciones académicas a adoptar prácticas similares, contribuyendo a un avance significativo en la reproducibilidad y transparencia en todas las disciplinas científicas. 2.3 Mejorar la Confiabilidad de la Investigación Para prevenir la mala práctica en la investigación, es necesario fortalecer las normas para compartir datos, fomentar la transparencia y la reproducibilidad. Este libro tiene como objetivo abordar estos problemas y mejorar la confianza en el trabajo empírico y en la investigación. References Chang, Andrew C, and Phillip Li. 2015. “Is Economics Research Replicable? Sixty Published Papers from Thirteen Journals Say’usually Not’.” Dewald, William G, Jerry G Thursby, and Richard G Anderson. 1986. “Replication in Empirical Economics: The Journal of Money, Credit and Banking Project.” The American Economic Review, 587–603. McCullough, Bruce D, and Hrishikesh D Vinod. 2003. “Verifying the Solution from a Nonlinear Solver: A Case Study.” American Economic Review 93 (3): 873–92. "],["invetica.html", " 3 Investigación Ética 3.1 Normas mertonianas para una investigación ética 3.2 Normas en la práctica 3.3 Problemas", " 3 Investigación Ética En este capítulo discutiremos el ethos de la investigación, es decir, los valores que deberían guiar la práctica científica. La ética en la investigación es fundamental para garantizar que el conocimiento generado sea confiable, válido y beneficioso para la sociedad. En este contexto, las normas mertonianas, propuestas por el sociólogo Robert K. Merton en 1942, representan uno de los marcos más influyentes y perdurables en la discusión sobre la ética en la investigación. Merton veía la ciencia como un sistema extremadamente eficiente para producir conocimiento, y su discusión sobre el ethos de la ciencia fue un esfuerzo por explicar por qué la ciencia funcionaba tan bien. Los investigadores han sostenido durante mucho tiempo que los valores de apertura y replicación son fundamentales para lo que hacen, pero en la práctica no siempre ha estado a la altura de esos ideales. Merton situaba a los científicos en un sistema social con un conjunto de normas y describía los incentivos que enfrentan los investigadores individuales al actuar dentro de esa estructura. Las normas tienen un carácter dual: los incentivos proporcionados por un sistema bien estructurado apoyan un comportamiento que se adhiere a las normas, pero el sistema también funciona porque los actores internalizan las normas: las aceptan. Los cuatro valores fundamentales de la investigación científica que Merton articula son universalismo, comunalidad, desinterés y escepticismo organizado. Las normas mertonianas proporcionan un marco ético esencial para la práctica de la ciencia, asegurando que la búsqueda del conocimiento se realice de manera justa, abierta y responsable. Es seguro decir que muchos (si no la mayoría) de los estudiantes de posgrado, donde nos incluimos, nunca reciben una formación formal en el ethos de la investigación científica que Merton discute. En la mayoría de los casos, los estudiantes simplemente asimilan los valores, expectativas y normas predominantes de los investigadores a través de su asesor, otros profesores y compañeros de estudio. Los aspirantes a científicos sociales a menudo simplemente absorben elementos del `ethos científico mientras interactúan con colegas, pero existe la preocupación de que también se puedan transmitir lecciones negativas de esta manera. Al adherirse a estos principios, los científicos contribuyen no solo al avance del conocimiento, sino también al bienestar y al progreso de la sociedad en su conjunto. A continuación, exploraremos las normas mertonianas para una investigación ética. 3.1 Normas mertonianas para una investigación ética 3.1.1 Universalismo El principio del universalismo es uno de los pilares fundamentales en la ética de la investigación científica según las normas mertonianas. Esta norma sostiene que las afirmaciones científicas deben evaluarse con criterios impersonales y universales, sin importar quién las haga. El conocimiento científico debe ser juzgado únicamente por su validez y mérito intrínseco, independientemente de la nacionalidad, género, religión, posición social o cualquier otra característica personal del científico. El universalismo es crucial porque promueve la objetividad y la equidad en la evaluación de los descubrimientos científicos. Al aplicar criterios universales, se asegura que el conocimiento científico sea accesible y evaluado de manera justa, evitando los prejuicios y la discriminación. Este principio fomenta un entorno en el que las ideas y los resultados pueden ser evaluados y aceptados basándose en evidencia empírica y razonamiento lógico, no en la autoridad o el prestigio del investigador. Una implicación importante es que las sociedades que promueven la igualdad de oportunidades educativas pueden experimentar un progreso científico más rápido. Cuando personas de diversos orígenes, independientemente de su género, etnia, religión, sexualidad o antecedentes académicos, pueden participar en la investigación, se enriquece el aprendizaje y el avance científico. Restringir el acceso a la formación científica excluye a grupos completos, empobreciendo el esfuerzo científico. A pesar de su importancia, la implementación del universalismo no está exenta de desafíos. Los prejuicios implícitos, las redes de poder y la desigualdad de recursos entre diferentes grupos y regiones pueden influir en la visibilidad y la aceptación de ciertos trabajos científicos. Además, la accesibilidad a recursos como financiamiento, equipos y formación avanzada puede variar significativamente, afectando la capacidad de algunos investigadores para contribuir al conocimiento científico global. 3.1.2 Comunalismo Este principio sostiene que los resultados del trabajo científico deben ser compartidos libremente con la comunidad científica y con la sociedad en general. En otras palabras, el conocimiento generado a través de la investigación científica no debe ser propiedad exclusiva del investigador, sino que debe ser un bien común accesible para todos. En otras palabras, y en marcado contraste con muchas otras formas de propiedad fuera de la investigación, el ethos científico exige que el conocimiento generado por la investigación pertenezca a toda la comunidad y no solo a quienes lo descubren. El comunalismo es vital porque promueve la transparencia, la colaboración y el progreso continuo en la ciencia. Al compartir los resultados y los datos de la investigación, se facilita la verificación de los hallazgos, la replicación de los estudios y la acumulación colectiva de conocimientos. Esta práctica también fomenta un ambiente de colaboración en lugar de competencia desleal, permitiendo a los científicos construir sobre el trabajo de otros y acelerar el avance científico. A pesar de sus beneficios, el comunalismo enfrenta varios desafíos. Entre ellos se encuentran la protección de la propiedad intelectual, ya que los investigadores y las instituciones a veces son reacios a compartir sus resultados debido a preocupaciones sobre la propiedad intelectual y los derechos de autor. Además, los costos de publicación en revistas de acceso abierto pueden ser elevados, lo que limita la capacidad de algunos investigadores para compartir sus hallazgos. Por último, la competencia académica y la presión por publicar y obtener financiación pueden llevar a algunos investigadores a ser menos abiertos con sus datos y resultados. 3.1.3 Desinterés La norma mertoniana del desinterés en la investigación ética establece que los científicos deben actuar con imparcialidad y objetividad, buscando el conocimiento por el bien común y no por beneficios personales o intereses privados. En otras palabras, los científicos deben estar motivados por la curiosidad intelectual y el deseo de contribuir al conocimiento colectivo, en lugar de por ganancias personales, fama o poder. Este principio implica también que el investigador ético debe informar los resultados tal como son, incluso si esto perjudica su reputación, contradice el conocimiento establecido o enfada a otras personas. El desinterés es crucial para mantener la integridad y la credibilidad de la ciencia. Cuando los científicos se adhieren a este principio, se reduce el riesgo de sesgos, manipulaciones de datos y conflictos de interés que pueden distorsionar los resultados y comprometer la calidad de la investigación. El desinterés fomenta la confianza pública en la ciencia, asegurando que los hallazgos y conclusiones sean genuinos y basados en evidencias sólidas. Sin embargo, a pesar de su importancia, la implementación del desinterés enfrenta varios desafíos. Los investigadores pueden enfrentar presiones externas de patrocinadores, instituciones académicas o la industria para obtener resultados favorables o que apoyen ciertos intereses. Además, la intensa competencia por financiación, publicaciones y reconocimiento puede tentar a algunos científicos a priorizar sus intereses personales sobre el bien común. Por último, no todos los conflictos de interés son fácilmente identificables o declarados, lo que puede comprometer la objetividad de la investigación. 3.1.4 Escepticismo Organizado Este principio establece que los científicos deben adoptar una actitud crítica y cuestionadora hacia las afirmaciones y teorías científicas, incluidas las propias. Una característica fundamental del enfoque de los investigadores científicos es que no deben aceptar las cosas al pie de la letra: necesitan ver pruebas. El escepticismo organizado implica someter todas las afirmaciones a un riguroso escrutinio y verificación, promoviendo la revisión por pares, la replicación de estudios y la evaluación continua de los resultados. Esto significa que los científicos no deben limitarse a temas socialmente aceptables ni a lo que las autoridades consideran adecuado estudiar: el ideal es examinar críticamente todo. A pesar de sus beneficios, el escepticismo organizado enfrenta varios desafíos. Los científicos pueden tener sesgos personales o estar influenciados por la opinión dominante en su campo, lo que puede dificultar la evaluación objetiva de nuevas ideas. Además, la presión por publicar rápidamente y obtener financiación puede llevar a algunos investigadores a no someter sus trabajos a un escrutinio suficientemente riguroso. Asimismo, las ideas verdaderamente innovadoras pueden ser rechazadas inicialmente por la comunidad científica debido a su novedad y a la dificultad de encajarlas en el paradigma existente. Estos desafíos resaltan la importancia de mantener un equilibrio entre el escepticismo y la apertura a nuevas perspectivas en la investigación científica. En última instancia, el escepticismo organizado no solo fortalece la calidad de la ciencia, sino que también fomenta un entorno en el que las ideas pueden ser rigurosamente probadas y evaluadas, garantizando que solo las teorías más robustas y bien fundamentadas sean aceptadas. Este enfoque crítico y abierto es esencial para el avance del conocimiento y para asegurar que la ciencia continúe siendo una herramienta confiable y efectiva para comprender el mundo. 3.2 Normas en la práctica Una camino para entender lo que piensa y hacen los investigadores es preguntarles directamente. Esto es lo que hicieron Anderson, Martinson, and De Vries (2007) en su trabajo titulado “Normative dissonance in science: Results from a national survey of US scientists”. En este trabajo investigaron la disonancia normativa en la ciencia, es decir, la discrepancia entre los ideales normativos ampliamente aceptados y las percepciones de los científicos sobre su propio comportamiento y el de otros. Para ello utilizando respuestas de una encuesta a 3,247 científicos en etapas iniciales y en la mitad de sus carreras, financiados por los Institutos Nacionales de Salud (NIH) de EE. UU. El NIH financia una amplia gama de investigadores, desde científicos de laboratorio en investigación biomédica hasta científicos sociales en muchas disciplinas cuyo trabajo trata temas de salud. Entonces, aunque no es una muestra completamente representativa de todos los académicos, sí cubre una gran variedad de campos. En este trabajo ademas de preguntarle sobre las cuatro normas de Merton, agrego dos valores adicionales: Gobernanza y Calidad. Al mismo tiempo emparejó cada uno con una “contranorma” que los académicos han identificado como existentes en la comunidad investigadora. Estas seis parejas de normas y contranormas se describen en la tabla 3.2.1. Por ejemplo, la contranorma del universalismo es el particularismo, que representa una falta de apertura a diferentes tipos de personas o investigadores, y específicamente la creencia de que la evidencia científica debe ser juzgada principalmente en función del historial de investigación del investigador en lugar de la calidad de la evidencia en sí. 3.2.1 Normas y Contranormas en la Ciencia Norma Descripción Contranorma Descripción Comunalidad Los científicos comparten abiertamente sus hallazgos con colegas. Secreto Los científicos protegen sus hallazgos más recientes para asegurar prioridad en la publicación, patente o aplicaciones. Universalismo Los científicos evalúan la investigación solo en función de su mérito. Particularismo Los científicos evalúan el nuevo conocimiento y sus aplicaciones basándose en la reputación y productividad pasada del individuo o grupo de investigación. Desinteresado Los científicos están motivados por el deseo de conocimiento y descubrimiento. Interesado Los científicos compiten con otros en el mismo campo por financiamiento y reconocimiento de sus logros. Escepticismo Organizado Los científicos consideran todas las nuevas evidencias, hipótesis, teorías e innovaciones, incluso aquellas que desafían o contradicen su propio trabajo. Dogmatismo Organizado Los científicos invierten sus carreras en promover sus hallazgos, teorías o innovaciones más importantes. Gobernanza Los científicos son responsables de la dirección y control de la ciencia a través de la gobernanza, la autorregulación y la revisión por pares. Administración Los científicos dependen de los administradores para dirigir la empresa científica a través de decisiones de gestión. Calidad Los científicos juzgan las contribuciones de los demás a la ciencia principalmente en función de la calidad. Cantidad Los científicos evalúan el trabajo de los demás principalmente en función del número de publicaciones y subvenciones. Nota: Esta tabla fue adaptada de Anderson, Martinson, and De Vries (2007) La figura @ref(tab:anderson_fig) muestra los porcentajes de los científicos en dos etapas de su carrera (inicio y mitad) que tienen puntuaciones normativas y contranormativas en tres categorías: suscripción, comportamiento propio y comportamiento de otros. 3.2.2 Normas versus contranormas en la práctica Nota: Esta figura fue tomada de Anderson, Martinson, and De Vries (2007) Esta figura subraya la desconexión entre las normas a las que los científicos suscriben y lo que perciben como el comportamiento típico, especialmente en el comportamiento de otros científicos, lo que refleja la disonancia normativa en el entorno de investigación. En cuanto a la Suscripción a Normas (Subscription), la mayoría (aproximadamente 90%) de los científicos en la etapa de Mitad de Carrera suscriben a las normas (barra gris), con muy pocos teniendo puntuaciones iguales (rayada) o menores (negra) en comparación con las contranormas. Para los científicos en Inicio de Carrera, la situación es similar: una gran mayoría suscribe a las normas, con pocos teniendo puntuaciones iguales o menores en comparación con las contranormas. En términos de Comportamiento Propio (Own Behavior), aunque la mayoría de los científicos en Mitad de Carrera tienen puntuaciones normativas mayores que las contranormativas, hay una proporción significativa con puntuaciones iguales o menores en comparación con las contranormas. Este patrón se repite en los científicos en Inicio de Carrera, pero con una mayor proporción de científicos con puntuaciones iguales o menores en comparación con las contranormas. Respecto al Comportamiento de Otros (Others’ Behavior), una mayoría de los científicos en Mitad de Carrera perciben el comportamiento típico de otros científicos como más contranormativo que normativo. Esta percepción es aún más marcada entre los científicos en Inicio de Carrera, con una gran mayoría percibiendo el comportamiento de otros como más contranormativo que normativo. Existe una disonancia significativa entre los ideales normativos y las percepciones del comportamiento real, tanto propio como de otros, siendo más pronunciada en la percepción del comportamiento de otros científicos. Los científicos en ambientes más competitivos tienden a ver un comportamiento más contranormativo, lo cual crea una fuente persistente de tensión y estrés en la comunidad científica. Esta figura subraya la desconexión entre las normas a las que los científicos suscriben y lo que perciben como el comportamiento típico, especialmente en el comportamiento de otros científicos, lo que refleja la disonancia normativa en el entorno de investigación. Sin embargo, surge la pregunta de cuál parte de la figura deberíamos creer: la parte media, que es mixta pero en general apoya las normas, o la parte inferior, que presenta una visión pesimista del campo de la investigación en su conjunto. Es posible que la última sea demasiado pesimista. Tal vez todos escuchan sobre unos pocos “casos malos”, como los casos de fraude discutidos en el primer capítulo, y a partir de ahí condenan injustamente el estado de la ética en todo su campo. 3.3 Problemas En el trabajo empírico una preocupación importante son los falsos positivos, que como ilustra Ioannidis (2005) es un problema mucho más importante que lo que se había pensado previamente. El problema de falsos positivos está íntimamente ligado al sesgo de publicación y búsqueda de especificación. Un ejemplo humorístico, pero muy ilustrativo de esta problemática, es el cómic de XKCD titulado “Significant”. En este cómic, un grupo de investigadores prueba la hipótesis de que comer jellybeans causa acné, realizando múltiples pruebas con diferentes colores de jellybeans. Después de 20 pruebas, finalmente encuentran un color (verde) que muestra una asociación significativa con el acné, aunque esta asociación sea un falso positivo debido al simple azar. Este escenario refleja claramente el problema del sesgo de publicación y la búsqueda de especificación. El sesgo de publicación ocurre cuando algunos estudios son más propensos a ser publicados que otros en función de sus resultados. En el caso de los jellybeans, si consideramos que se realizaron 20 estudios separados, sólo se publicaría aquel que mostró un resultado significativo, ignorando los otros 19 que no encontraron ninguna asociación. La búsqueda de especificación, por otro lado, ocurre cuando los investigadores exploran múltiples formas de analizar los datos dentro de un mismo estudio, y sólo reportan aquellas que muestran resultados significativos. Si imaginamos que el investigador del cómic probó 20 formas diferentes de dividir la muestra hasta encontrar una que arrojara un resultado significativo, estaríamos frente a un caso de búsqueda de especificación. Estos dos fenómenos están estrechamente relacionados: la anticipación del sesgo de publicación por parte de los investigadores fomenta la búsqueda de especificación, ya que los investigadores se sienten presionados a encontrar resultados que sean “publicables”. John Ioannidis, en su influyente artículo “Why Most Published Research Findings Are False”, argumenta que debido a estos problemas, muchos de los hallazgos publicados en la literatura científica son falsos positivos. Según Ioannidis, la combinación de estudios con bajo poder estadístico, la flexibilidad en los diseños de estudio y los análisis, y el sesgo de publicación, contribuyen a una alta tasa de resultados falsos en la investigación científica. El cómic de XKCD sirve como una representación visual simple pero potente de estos problemas. Nos recuerda que debemos ser críticos con los resultados publicados y conscientes de los sesgos y prácticas que pueden distorsionalos. Al abordar estos problemas, es esencial mejorar la transparencia en la investigación, promover la publicación de todos los resultados, y adoptar prácticas estadísticas más rigurosas para reducir la prevalencia de falsos positivos y fortalecer la fiabilidad de nuestros hallazgos. Falsos Positivos en Tests de Hipótesis Una hipótesis (por ejemplo, “El aumento del salario mínimo está asociado con una disminución en la tasa de desempleo”) es verdadera o falsa en el mundo real. Debido a que el investigador no puede estudiar a todas las personas afectadas, debe probar la hipótesis en una muestra de esa población objetivo. No importa cuántos datos recoja el investigador, nunca podrá probar (o refutar) su hipótesis de manera absoluta. Siempre existirá la necesidad de hacer inferencias sobre los fenómenos en la población a partir de los eventos observados en la muestra (Banerjee et al. 2009). Los errores son inevitables hasta cierto punto en el proceso de tests de hipótesis debido a las limitaciones inherentes a la investigación y al análisis de datos. Por ejemplo, pensemos en la siguiente analogía, al igual que un juez en un juicio, el investigador debe tomar una decisión basada en la evidencia disponible. Un juez comienza presumiendo la inocencia del acusado y solo rechaza esta presunción si hay pruebas suficientes más allá de una duda razonable. De manera similar, el investigador empieza asumiendo la hipótesis nula (\\(H_0\\)). Utilizando pruebas estadísticas, el investigador debe determinar si hay suficiente evidencia para rechazar \\(H_0\\) en favor de la hipótesis alternativa (\\(H_1\\)). Aun así, siempre existe la posibilidad de error, condenando a un inocente (error de Tipo I) o liberando a un culpable (error de Tipo II), lo cual refleja la naturaleza incierta de la inferencia estadística. Podemos resumir este proceso en la siguiente tabla de contingencia: Decisión sobre \\(H_0\\) La hipótesis nula (\\(H_0\\)) es verdadera La hipótesis nula (\\(H_0\\)) es falsa No rechazar \\(H_0\\) Inferencia correcta (verdadero negativo)(probabilidad = \\(1−\\alpha\\)) Error de Tipo II (falso negativo)(probabilidad = \\(\\beta\\)) Rechazar \\(H_0\\) Error de Tipo I (falso positivo)(probabilidad = \\(\\alpha\\)) Inferencia correcta (verdadero positivo)(probabilidad = \\(1−\\beta\\)) En el contexto de los tests de hipótesis, un falso positivo ocurre cuando se rechaza incorrectamente la hipótesis nula (\\(H_0\\)) a favor de la hipótesis alternativa (\\(H_1\\)). En otras palabras, el test indica un resultado significativo cuando, en realidad, no lo es. Este error es conocido como error de Tipo I y se denota por \\(\\alpha\\), que representa la probabilidad de cometer un falso positivo. En otras palabras, si el test no lleva a No rechazar \\(H_0\\) puede ser que estemos: - Haciendo: Inferencia correcta (verdadero negativo) (probabilidad = \\(1−\\alpha\\)): La prueba correctamente no rechaza \\(H_0\\) cuando \\(H_0\\) es verdadera. Es la probabilidad de no cometer un error de Tipo I. - Cometiendo Error de Tipo II (falso negativo) (probabilidad = \\(\\beta\\)): La prueba no rechaza \\(H_0\\) cuando \\(H_1\\) es verdadera. Este es el error de Tipo II. En casos contrario, si Rechazamos \\(H_0\\) puede que estemos: - Cometiendo Error de Tipo I (falso positivo) (probabilidad = \\(\\alpha\\)): La prueba incorrectamente rechaza \\(H_0\\) cuando \\(H_0\\) es verdadera. Esta es la tasa de error de Tipo I. - Haciendo Inferencia correcta (verdadero positivo) (probabilidad = \\(1−\\beta\\)): La prueba correctamente rechaza \\(H_0\\) cuando \\(H_1\\) es verdadera. Esta es la potencia del test, que es 1 menos la probabilidad de cometer un error de Tipo II (\\(\\beta\\)). En resumen, los falsos positivos (\\(\\alpha\\)) son situaciones donde el test sugiere incorrectamente la existencia de Anderson, Melissa S, Brian C Martinson, and Raymond De Vries. 2007. “Normative Dissonance in Science: Results from a National Survey of US Scientists.” Journal of Empirical Research on Human Research Ethics 2 (4): 3–14. Banerjee, Amitav, UB Chitnis, SL Jadhav, JS Bhawalkar, and S Chaudhury. 2009. “Hypothesis Testing, Type i and Type II Errors.” Industrial Psychiatry Journal 18 (2): 127–31. Chang, Andrew C, and Phillip Li. 2015. “Is Economics Research Replicable? Sixty Published Papers from Thirteen Journals Say’usually Not’.” Dewald, William G, Jerry G Thursby, and Richard G Anderson. 1986. “Replication in Empirical Economics: The Journal of Money, Credit and Banking Project.” The American Economic Review, 587–603. Ioannidis, John PA. 2005. “Why Most Published Research Findings Are False.” PLoS Medicine 2 (8): e124. McCullough, Bruce D, and Hrishikesh D Vinod. 2003. “Verifying the Solution from a Nonlinear Solver: A Case Study.” American Economic Review 93 (3): 873–92. References Anderson, Melissa S, Brian C Martinson, and Raymond De Vries. 2007. “Normative Dissonance in Science: Results from a National Survey of US Scientists.” Journal of Empirical Research on Human Research Ethics 2 (4): 3–14. Banerjee, Amitav, UB Chitnis, SL Jadhav, JS Bhawalkar, and S Chaudhury. 2009. “Hypothesis Testing, Type i and Type II Errors.” Industrial Psychiatry Journal 18 (2): 127–31. Ioannidis, John PA. 2005. “Why Most Published Research Findings Are False.” PLoS Medicine 2 (8): e124. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
